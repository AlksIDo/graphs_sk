{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1be1351-3f23-4504-940e-93283c80c7e3",
   "metadata": {},
   "source": [
    "# Что не сработало"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd978a-549c-4664-92b9-3c932236ac30",
   "metadata": {},
   "source": [
    "Попробовал использовать torch_geometric для решения задачи, сделал достаточно сложные архитектуры, но модель работала хуже бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5006375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:42:15.998788Z",
     "start_time": "2021-08-03T15:42:15.992212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd7548-a1e0-49f1-adcc-efd7f68e608f",
   "metadata": {},
   "source": [
    "# Test graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6cd2681-2b4d-43d5-b6c6-4bc23e01a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.nn import GATConv, GraphConv\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import (\n",
    "    ChebConv,\n",
    "    GATConv,\n",
    "    GCNConv,\n",
    "    GraphConv,\n",
    "    NNConv,\n",
    "    global_mean_pool,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c03afe3-d5ec-411b-a915-2ee87b986a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"02-pdbbind-refined.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6af9d04f-2449-4cee-90f6-f17998562a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"e_predict\"] = df[\"e_exp\"] * 2 ** (-(df[\"rmsd\"] ** 2) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41db38f2-f717-4db2-92d6-1ade82dc1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"e_predict\"] = df[\"e_predict\"].map(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b49be75-b4fe-4cf0-8bf7-26c6f068d2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>run</th>\n",
       "      <th>pose</th>\n",
       "      <th>nfrb</th>\n",
       "      <th>e_docking</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>eLJ</th>\n",
       "      <th>emetal</th>\n",
       "      <th>eHB</th>\n",
       "      <th>eelec</th>\n",
       "      <th>etors</th>\n",
       "      <th>is_good</th>\n",
       "      <th>e_exp</th>\n",
       "      <th>name</th>\n",
       "      <th>e_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184l</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.32687</td>\n",
       "      <td>0.55437</td>\n",
       "      <td>-1.41440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20612</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.444844</td>\n",
       "      <td>184l-0-0.gml</td>\n",
       "      <td>6.110599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184l</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.15635</td>\n",
       "      <td>1.80368</td>\n",
       "      <td>-1.34504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26135</td>\n",
       "      <td>-0.00049</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.444844</td>\n",
       "      <td>184l-0-1.gml</td>\n",
       "      <td>3.667584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184l</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.03622</td>\n",
       "      <td>4.19935</td>\n",
       "      <td>-1.37091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36299</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.444844</td>\n",
       "      <td>184l-0-2.gml</td>\n",
       "      <td>0.303446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184l</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.05864</td>\n",
       "      <td>4.24878</td>\n",
       "      <td>-1.40106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37758</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.444844</td>\n",
       "      <td>184l-0-3.gml</td>\n",
       "      <td>0.282263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184l</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.12396</td>\n",
       "      <td>4.24426</td>\n",
       "      <td>-1.41376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21307</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.444844</td>\n",
       "      <td>184l-0-4.gml</td>\n",
       "      <td>0.284147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pdb  run  pose  nfrb  e_docking     rmsd      eLJ  emetal      eHB  \\\n",
       "0  184l    0     0     2   -5.32687  0.55437 -1.41440     0.0  0.20612   \n",
       "1  184l    0     1     2   -5.15635  1.80368 -1.34504     0.0  0.26135   \n",
       "2  184l    0     2     2   -5.03622  4.19935 -1.37091     0.0  0.36299   \n",
       "3  184l    0     3     2   -5.05864  4.24878 -1.40106     0.0  0.37758   \n",
       "4  184l    0     4     2   -5.12396  4.24426 -1.41376     0.0  0.21307   \n",
       "\n",
       "     eelec   etors  is_good     e_exp          name  e_predict  \n",
       "0 -0.00003  0.2352        1 -6.444844  184l-0-0.gml   6.110599  \n",
       "1 -0.00049  0.2352        0 -6.444844  184l-0-1.gml   3.667584  \n",
       "2  0.00039  0.2352        0 -6.444844  184l-0-2.gml   0.303446  \n",
       "3  0.00002  0.2352        0 -6.444844  184l-0-3.gml   0.282263  \n",
       "4 -0.00005  0.2352        0 -6.444844  184l-0-4.gml   0.284147  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16008e16-6789-406a-9bf6-319264d77ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data/1a28-2-0.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40067d30-0334-4244-86d9-f5b780246b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[460.,   3.,   0.,   0.,   0.],\n",
       "       [471.,   3.,   0.,   0.,   0.],\n",
       "       [492.,   0.,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [ 20.,   0.,   1.,   1.,   0.],\n",
       "       [ 21.,   3.,   1.,   1.,   0.],\n",
       "       [ 22.,   0.,   1.,   1.,   0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"node_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62479486-c3d5-4adc-be61-ef51b0c0a136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T14:59:24.070143Z",
     "start_time": "2021-06-23T14:58:45.870Z"
    }
   },
   "outputs": [],
   "source": [
    "folder = \"data/\"\n",
    "node_ohe = OHE(categories=[list(range(23)), [0, 1], [0, 1]])\n",
    "edge_ohe = OHE(categories=[[0, 1]])\n",
    "graphs = []\n",
    "idx_arr = []\n",
    "y_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ed999f6-23ef-447d-abab-0a174d845217",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T14:59:24.070143Z",
     "start_time": "2021-06-23T14:58:45.870Z"
    }
   },
   "outputs": [],
   "source": [
    "for num, fn in enumerate(os.listdir(folder)):\n",
    "    if fn.endswith(\".npz\"):\n",
    "        data = np.load(folder + fn)\n",
    "        X = torch.tensor(node_ohe.fit_transform(data[\"node_data\"][:, 1:4]).todense())\n",
    "\n",
    "        A = edge_ohe.fit_transform(data[\"edge_data\"][:, 1:]).todense()\n",
    "        E = torch.tensor(np.hstack((data[\"edge_data\"][:, :1], A)))\n",
    "\n",
    "        pg_data = Data(\n",
    "            edge_index=torch.tensor(data[\"edges\"][:, 0:2]).t().contiguous().long(),\n",
    "            x=X.float(),\n",
    "            edge_attr=E.float(),\n",
    "            y=torch.tensor(\n",
    "                df[df[\"name\"] == fn.replace(\".npz\", \".gml\")][\"e_predict\"].item()\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        idx_arr.append(num)\n",
    "        y_arr.append(df[df[\"name\"] == fn.replace(\".npz\", \".gml\")][\"e_predict\"].item())\n",
    "\n",
    "        graphs.append(pg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59cc24aa-4e6b-4a26-8dc4-db240cedc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import compress_pickle\n",
    "# compress_pickle.dump(graphs, \"data/graphs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2285a4-22aa-4447-8063-3e56a80aa4d8",
   "metadata": {},
   "source": [
    "# Train/test split, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa0b8946-e60e-4f30-a5c4-957f531835a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    graphs,\n",
    "    y_arr,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=[np.exp(i.y.cpu().numpy()) > 0.5 for i in graphs],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c3cd0a5-94f8-4f00-a3ec-4a508e43173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph_data = self.graphs[idx]\n",
    "\n",
    "        graph_data.y_exp = torch.exp(deepcopy(graph_data.y))\n",
    "\n",
    "        graph_data.y_int = torch.round(deepcopy(graph_data.y_exp)).float()\n",
    "\n",
    "        return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e41a069c-d0b6-4961-844c-df4cf6a534d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphDataset(X_train)\n",
    "test_dataset = GraphDataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ce9bb3c-bae5-4579-814b-d04634033a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[517, 27], edge_index=[2, 22851], edge_attr=[22851, 3], y=0.15911602973937988, y_exp=1.1724740266799927, y_int=1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc900c2f-e0ce-485e-9927-50bf795e5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a44a4f1e-1c70-440a-a964-5f0d169ed68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(train_dataset, test_dataset):\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    prediction = np.mean([i.y.item() for i in train_dataset])\n",
    "\n",
    "    true_labels = [i.y.item() for i in test_dataset]\n",
    "    pred_labels = [prediction for i in range(len(test_dataset))]\n",
    "\n",
    "    return (\n",
    "        mean_squared_error(pred_labels, true_labels, squared=True),\n",
    "        r2_score(pred_labels, true_labels),\n",
    "        criterion(torch.tensor(pred_labels), torch.tensor(true_labels)).item(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "408a7b80-c16f-4605-8209-27a982e02272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.563990328446478, -4.3424589920815715e+31, 8.563990328446478)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d1844-cfc2-4016-8eb6-8715f21bcf37",
   "metadata": {},
   "source": [
    "Бейзлайн модель при текущем сплите отрабатывает на 8.564 RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f56e715-7701-4442-b138-323454e62313",
   "metadata": {},
   "source": [
    "## Простая графовая регрессионная модель pytorch_geometric без использования edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d76e1247-6b0f-4c8e-915a-2250d0025e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GraphConv(27, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin1): Linear(in_features=64, out_features=30, bias=True)\n",
      "  (lin2): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "22013\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, GraphConv, NNConv, global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, node_feature_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(node_feature_channels, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin1 = Linear(hidden_channels, 30)\n",
    "        self.lin2 = Linear(30, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # 1. Obtain node embeddings\n",
    "        x, edge_index, edge_attr, batch = (\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.edge_attr,\n",
    "            data.batch,\n",
    "        )\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GCN(hidden_channels=64, node_feature_channels=train_dataset.num_node_features)\n",
    "print(model)\n",
    "print(sum(p.numel() for p in model.parameters()))  # Не очень тяжелая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3f68f88-5d45-4dff-ab4c-ad2e7cdb675a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.837188720703125\n",
      "Validation loss: 4.703821659088135\n",
      "Train loss: 1.321024775505066\n",
      "Validation loss: 0.21944275498390198\n",
      "Train loss: 3.3927693367004395\n",
      "Validation loss: 3.650869369506836\n",
      "Train loss: 7.441938400268555\n",
      "Validation loss: 9.835693359375\n",
      "Train loss: 1.2197413444519043\n",
      "Validation loss: 0.7655764818191528\n",
      "Train loss: 1.7650243043899536\n",
      "Validation loss: 2.459132432937622\n",
      "Train loss: 5.909269332885742\n",
      "Validation loss: 2.240975856781006\n",
      "Train loss: 16.18610954284668\n",
      "Validation loss: 5.481194496154785\n",
      "Train loss: 3.1364128589630127\n",
      "Validation loss: 0.27945929765701294\n",
      "Train loss: 0.739136278629303\n",
      "Validation loss: 3.129793643951416\n",
      "Train loss: 8.18210220336914\n",
      "Validation loss: 0.4520628750324249\n",
      "Train loss: 6.439365863800049\n",
      "Validation loss: 1.3088550567626953\n",
      "Train loss: 0.4992656707763672\n",
      "Validation loss: 5.411246299743652\n",
      "Train loss: 0.08013726770877838\n",
      "Validation loss: 12.450654029846191\n",
      "Train loss: 0.2558259069919586\n",
      "Validation loss: 4.587270736694336\n",
      "Train loss: 1.3041611909866333\n",
      "Validation loss: 1.4440406560897827\n",
      "Train loss: 2.0285842418670654\n",
      "Validation loss: 8.381954193115234\n",
      "Train loss: 9.196626663208008\n",
      "Validation loss: 5.851426601409912\n",
      "Train loss: 2.7232468128204346\n",
      "Validation loss: 2.305760145187378\n",
      "Train loss: 7.046729564666748\n",
      "Validation loss: 8.433662414550781\n",
      "Train loss: 1.1724002361297607\n",
      "Validation loss: 2.3571906089782715\n",
      "Train loss: 4.360191822052002\n",
      "Validation loss: 0.44233810901641846\n",
      "Train loss: 0.7503715753555298\n",
      "Validation loss: 2.7736964225769043\n",
      "Train loss: 3.370008945465088\n",
      "Validation loss: 7.178251266479492\n",
      "Train loss: 3.8933515548706055\n",
      "Validation loss: 5.381596565246582\n",
      "Train loss: 0.6063439846038818\n",
      "Validation loss: 15.248151779174805\n",
      "Train loss: 19.825502395629883\n",
      "Validation loss: 0.23986704647541046\n",
      "Train loss: 1.4298442602157593\n",
      "Validation loss: 0.9659762382507324\n",
      "Train loss: 12.162008285522461\n",
      "Validation loss: 0.9955687522888184\n",
      "Train loss: 0.22045962512493134\n",
      "Validation loss: 1.1820300817489624\n",
      "Train loss: 24.695402145385742\n",
      "Validation loss: 9.751968383789062\n",
      "Train loss: 5.347747802734375\n",
      "Validation loss: 1.0501997470855713\n",
      "Train loss: 2.9356648921966553\n",
      "Validation loss: 0.12633009254932404\n",
      "Train loss: 0.4869270920753479\n",
      "Validation loss: 9.718465805053711\n",
      "Train loss: 39.59161376953125\n",
      "Validation loss: 3.8732986450195312\n",
      "Train loss: 4.112130165100098\n",
      "Validation loss: 13.809858322143555\n",
      "Train loss: 11.727046012878418\n",
      "Validation loss: 9.521656036376953\n",
      "Train loss: 0.4982934594154358\n",
      "Validation loss: 10.807641983032227\n",
      "Train loss: 0.5219929218292236\n",
      "Validation loss: 1.1190621852874756\n",
      "Train loss: 5.726892471313477\n",
      "Validation loss: 0.8430357575416565\n",
      "Train loss: 13.278995513916016\n",
      "Validation loss: 15.25548267364502\n",
      "Train loss: 2.392282485961914\n",
      "Validation loss: 1.792536735534668\n",
      "Train loss: 1.44515061378479\n",
      "Validation loss: 4.343501567840576\n",
      "Train loss: 0.4153969883918762\n",
      "Validation loss: 4.8041090965271\n",
      "Train loss: 3.1751089096069336\n",
      "Validation loss: 0.7231174111366272\n",
      "Train loss: 0.9165341854095459\n",
      "Validation loss: 1.274117350578308\n",
      "Train loss: 27.869823455810547\n",
      "Validation loss: 2.0906424522399902\n",
      "Train loss: 21.194778442382812\n",
      "Validation loss: 0.8082383275032043\n",
      "Train loss: 23.477252960205078\n",
      "Validation loss: 1.7621270418167114\n",
      "Train loss: 0.8065500855445862\n",
      "Validation loss: 0.9514937400817871\n",
      "Train loss: 0.7265723943710327\n",
      "Validation loss: 0.35431644320487976\n",
      "Train loss: 1.2272014617919922\n",
      "Validation loss: 1.779160976409912\n",
      "Train loss: 0.6730080246925354\n",
      "Validation loss: 0.37830254435539246\n",
      "Train loss: 0.704720139503479\n",
      "Validation loss: 0.3520505726337433\n",
      "Train loss: 0.6185100078582764\n",
      "Validation loss: 7.439160346984863\n",
      "Train loss: 0.16603434085845947\n",
      "Validation loss: 0.36941516399383545\n",
      "Train loss: 0.27717000246047974\n",
      "Validation loss: 5.292408466339111\n",
      "Train loss: 0.8851879835128784\n",
      "Validation loss: 0.43999236822128296\n",
      "Train loss: 0.16443897783756256\n",
      "Validation loss: 0.0422317311167717\n",
      "Train loss: 14.732139587402344\n",
      "Validation loss: 0.786719799041748\n",
      "Train loss: 1.6881877183914185\n",
      "Validation loss: 0.21134516596794128\n",
      "Train loss: 0.49855706095695496\n",
      "Validation loss: 4.856233596801758\n",
      "Train loss: 16.256643295288086\n",
      "Validation loss: 9.087958335876465\n",
      "Train loss: 4.109241008758545\n",
      "Validation loss: 0.6420265436172485\n",
      "Train loss: 0.3992677927017212\n",
      "Validation loss: 0.16070105135440826\n",
      "Train loss: 3.5950448513031006\n",
      "Validation loss: 2.1619341373443604\n",
      "Train loss: 0.12751945853233337\n",
      "Validation loss: 1.103165864944458\n",
      "Train loss: 0.26250946521759033\n",
      "Validation loss: 0.05983413755893707\n",
      "Train loss: 3.155829429626465\n",
      "Validation loss: 3.861159563064575\n",
      "Train loss: 1.3550622463226318\n",
      "Validation loss: 0.8178625106811523\n",
      "Train loss: 0.019291745498776436\n",
      "Validation loss: 15.897810935974121\n",
      "Train loss: 5.519032001495361\n",
      "Validation loss: 3.2671046257019043\n",
      "Train loss: 0.0969165489077568\n",
      "Validation loss: 1.034160852432251\n",
      "Train loss: 0.02904912270605564\n",
      "Validation loss: 0.8824012279510498\n",
      "Train loss: 6.335623264312744\n",
      "Validation loss: 1.6129412651062012\n",
      "Train loss: 1.0036793947219849\n",
      "Validation loss: 2.134232997894287\n",
      "Train loss: 1.763404130935669\n",
      "Validation loss: 4.983794212341309\n",
      "Train loss: 8.7981538772583\n",
      "Validation loss: 1.2866604328155518\n",
      "Train loss: 1.275285243988037\n",
      "Validation loss: 0.08956724405288696\n",
      "Train loss: 0.031224921345710754\n",
      "Validation loss: 9.880532264709473\n",
      "Train loss: 1.9538483619689941\n",
      "Validation loss: 0.16879844665527344\n",
      "Train loss: 0.25750452280044556\n",
      "Validation loss: 3.439983606338501\n",
      "Train loss: 0.779005765914917\n",
      "Validation loss: 42.34550094604492\n",
      "Train loss: 0.17719446122646332\n",
      "Validation loss: 0.08452526479959488\n",
      "Train loss: 0.3258292078971863\n",
      "Validation loss: 4.3266377449035645\n",
      "Train loss: 1.0216660499572754\n",
      "Validation loss: 0.423387348651886\n",
      "Train loss: 2.570634365081787\n",
      "Validation loss: 0.002839438384398818\n",
      "Train loss: 0.5389941334724426\n",
      "Validation loss: 0.946844220161438\n",
      "Train loss: 1.5580726861953735\n",
      "Validation loss: 0.3835912346839905\n",
      "Train loss: 6.816363334655762\n",
      "Validation loss: 0.876451313495636\n",
      "Train loss: 8.314672470092773\n",
      "Validation loss: 3.6488513946533203\n",
      "Train loss: 0.047018811106681824\n",
      "Validation loss: 15.124303817749023\n",
      "Train loss: 4.317039489746094\n",
      "Validation loss: 6.2977752685546875\n",
      "Train loss: 13.484928131103516\n",
      "Validation loss: 0.3388533592224121\n",
      "Train loss: 4.594512462615967\n",
      "Validation loss: 0.1969161033630371\n",
      "Train loss: 7.245954990386963\n",
      "Validation loss: 5.041772365570068\n",
      "Train loss: 0.5627286434173584\n",
      "Validation loss: 1.9530929327011108\n",
      "Train loss: 0.18177691102027893\n",
      "Validation loss: 4.919188022613525\n",
      "Train loss: 0.9088326692581177\n",
      "Validation loss: 0.5781844258308411\n",
      "Train loss: 0.6369085907936096\n",
      "Validation loss: 0.01063606794923544\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "device = \"cuda:2\"\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(out.view(-1, 1), data.y.view(-1, 1))  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "    print(f\"Train loss: {loss.item()}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        true = []\n",
    "        preds = []\n",
    "        for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            out = model(data)  # Perform a single forward pass.\n",
    "            val_loss = criterion(\n",
    "                out.view(-1, 1), data.y.view(-1, 1)\n",
    "            )  # Compute the loss.\n",
    "            true.extend(data.y.detach().cpu().numpy())\n",
    "            preds.extend(out.detach().cpu().numpy())\n",
    "        print(f\"Validation loss: {val_loss.item()}\")\n",
    "\n",
    "    return mean_squared_error(true, preds)\n",
    "\n",
    "\n",
    "rmse_history = []\n",
    "for epoch in range(100):\n",
    "    rmse_val = train()\n",
    "    rmse_history.append(rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06ce07d2-6e97-4605-b006-fe3207b3af70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, 20.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmse_history)\n",
    "plt.title(\"RMSE history for simple graph model\")\n",
    "plt.ylim([3, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb65c68-9d93-458b-960e-f824c700fb2b",
   "metadata": {},
   "source": [
    "В целом простая модель долго и тяжело сходится, бейзлайн слегка пробит <br>\n",
    "upd. Модель сходится до ~2.2 RMSE после 600+ эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3527cd5-2bf9-48cc-b573-bf75daea4c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0883672"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(rmse_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78effc42-729e-40e9-82af-4b970a3246e7",
   "metadata": {},
   "source": [
    "# Heavy model тяжелые модели, которые используют edge_features работают хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9791bba4-1299-4823-9c28-4994d23a6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import (\n",
    "    ChebConv,\n",
    "    DeepGCNLayer,\n",
    "    GCNConv,\n",
    "    GraphConv,\n",
    "    NNConv,\n",
    "    global_add_pool,\n",
    "    global_max_pool,\n",
    "    global_mean_pool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86e1e333-8f6d-43c0-b4c1-b4b74ee5e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDeeperGCN(\n",
      "  (node_encoder): GraphConv(27, 64)\n",
      "  (edge_encoder): Linear(in_features=3, out_features=64, bias=True)\n",
      "  (layers): ModuleList(\n",
      "    (0): DeepGCNLayer(block=res+)\n",
      "    (1): DeepGCNLayer(block=res+)\n",
      "    (2): DeepGCNLayer(block=res+)\n",
      "  )\n",
      "  (lin1): Linear(in_features=64, out_features=30, bias=True)\n",
      "  (lin2): Linear(in_features=30, out_features=15, bias=True)\n",
      "  (lin3): Linear(in_features=15, out_features=1, bias=True)\n",
      ")\n",
      "830271\n"
     ]
    }
   ],
   "source": [
    "class MapE2NxN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels):\n",
    "        super(MapE2NxN, self).__init__()\n",
    "        self.linear1 = Linear(in_channels, hidden_channels)\n",
    "        self.linear2 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = x.relu()\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDeeperGCN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_node_features,\n",
    "        num_edge_features,\n",
    "        node_hidden_channels,\n",
    "        edge_hidden_channels,\n",
    "        num_layers,\n",
    "        num_classes,\n",
    "    ):\n",
    "        super(MyDeeperGCN, self).__init__()\n",
    "\n",
    "        self.node_encoder = GraphConv(num_node_features, node_hidden_channels)\n",
    "        self.edge_encoder = Linear(num_edge_features, edge_hidden_channels)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(1, num_layers + 1):\n",
    "            conv = NNConv(\n",
    "                node_hidden_channels,\n",
    "                node_hidden_channels,\n",
    "                MapE2NxN(\n",
    "                    edge_hidden_channels,\n",
    "                    node_hidden_channels * node_hidden_channels,\n",
    "                    64,\n",
    "                ),\n",
    "            )\n",
    "            norm = nn.LayerNorm(node_hidden_channels)\n",
    "            act = nn.ELU(inplace=True)\n",
    "\n",
    "            layer = DeepGCNLayer(\n",
    "                conv, norm, act, block=\"res+\", dropout=0, ckpt_grad=False\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.lin1 = Linear(node_hidden_channels, 30)\n",
    "        self.lin2 = Linear(30, 15)\n",
    "        self.lin3 = Linear(15, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        batch = data.batch\n",
    "\n",
    "        # edge for paired nodes are excluded for encoding node\n",
    "        x = self.node_encoder(x, edge_index)  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        x = self.layers[0].conv(x, edge_index, edge_attr)\n",
    "\n",
    "        for layer in self.layers[1:]:\n",
    "            x = layer(x, edge_index, edge_attr)\n",
    "\n",
    "        x = self.layers[0].norm(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        x = F.elu(x)\n",
    "\n",
    "        return self.lin3(x)\n",
    "\n",
    "\n",
    "model = MyDeeperGCN(\n",
    "    train_dataset.num_node_features,\n",
    "    train_dataset.num_edge_features,\n",
    "    node_hidden_channels=64,\n",
    "    edge_hidden_channels=64,\n",
    "    num_layers=3,\n",
    "    num_classes=1,\n",
    ")\n",
    "print(model)\n",
    "print(sum(p.numel() for p in model.parameters()))  # Внушительная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad5d31e8-bc97-4fe0-b634-47b066a5e988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 87.17100524902344, EPOCH: 0\n",
      "Validation Accuracy: 3.8768470287323, EPOCH: 0\n",
      "Train Accuracy: 3.274113893508911, EPOCH: 1\n",
      "Validation Accuracy: 7.661032199859619, EPOCH: 1\n",
      "Train Accuracy: 19.66990852355957, EPOCH: 2\n",
      "Validation Accuracy: 55.43294143676758, EPOCH: 2\n",
      "Train Accuracy: 4.710487365722656, EPOCH: 3\n",
      "Validation Accuracy: 52.21293640136719, EPOCH: 3\n",
      "Train Accuracy: 11.187816619873047, EPOCH: 4\n",
      "Validation Accuracy: 6.224162578582764, EPOCH: 4\n",
      "Train Accuracy: 4.695056438446045, EPOCH: 5\n",
      "Validation Accuracy: 7.767773628234863, EPOCH: 5\n",
      "Train Accuracy: 3.8167476654052734, EPOCH: 6\n",
      "Validation Accuracy: 6.035558223724365, EPOCH: 6\n",
      "Train Accuracy: 4.211737632751465, EPOCH: 7\n",
      "Validation Accuracy: 18.66333770751953, EPOCH: 7\n",
      "Train Accuracy: 53.283477783203125, EPOCH: 8\n",
      "Validation Accuracy: 42.96971893310547, EPOCH: 8\n",
      "Train Accuracy: 3.2188210487365723, EPOCH: 9\n",
      "Validation Accuracy: 22.6881046295166, EPOCH: 9\n",
      "Train Accuracy: 14.141031265258789, EPOCH: 10\n",
      "Validation Accuracy: 3.260568380355835, EPOCH: 10\n",
      "Train Accuracy: 3.7056384086608887, EPOCH: 11\n",
      "Validation Accuracy: 12.190534591674805, EPOCH: 11\n",
      "Train Accuracy: 7.474740028381348, EPOCH: 12\n",
      "Validation Accuracy: 4.093728065490723, EPOCH: 12\n",
      "Train Accuracy: 6.980953693389893, EPOCH: 13\n",
      "Validation Accuracy: 56.837074279785156, EPOCH: 13\n",
      "Train Accuracy: 2.50496244430542, EPOCH: 14\n",
      "Validation Accuracy: 82.60433959960938, EPOCH: 14\n",
      "Train Accuracy: 16.70121955871582, EPOCH: 15\n",
      "Validation Accuracy: 51.672733306884766, EPOCH: 15\n",
      "Train Accuracy: 9.195782661437988, EPOCH: 16\n",
      "Validation Accuracy: 68.1214599609375, EPOCH: 16\n",
      "Train Accuracy: 7.068854331970215, EPOCH: 17\n",
      "Validation Accuracy: 9.387069702148438, EPOCH: 17\n",
      "Train Accuracy: 5.162670612335205, EPOCH: 18\n",
      "Validation Accuracy: 11.766819953918457, EPOCH: 18\n",
      "Train Accuracy: 4.8772382736206055, EPOCH: 19\n",
      "Validation Accuracy: 6.933581829071045, EPOCH: 19\n",
      "Train Accuracy: 4.312813758850098, EPOCH: 20\n",
      "Validation Accuracy: 35.84087371826172, EPOCH: 20\n",
      "Train Accuracy: 6.098948001861572, EPOCH: 21\n",
      "Validation Accuracy: 6.788071155548096, EPOCH: 21\n",
      "Train Accuracy: 33.029151916503906, EPOCH: 22\n",
      "Validation Accuracy: 3.5654373168945312, EPOCH: 22\n",
      "Train Accuracy: 5.340447425842285, EPOCH: 23\n",
      "Validation Accuracy: 9.070455551147461, EPOCH: 23\n",
      "Train Accuracy: 13.594452857971191, EPOCH: 24\n",
      "Validation Accuracy: 2.153594493865967, EPOCH: 24\n",
      "Train Accuracy: 5.951552391052246, EPOCH: 25\n",
      "Validation Accuracy: 1.0628594160079956, EPOCH: 25\n",
      "Train Accuracy: 16.961956024169922, EPOCH: 26\n",
      "Validation Accuracy: 3.0717883110046387, EPOCH: 26\n",
      "Train Accuracy: 3.5334689617156982, EPOCH: 27\n",
      "Validation Accuracy: 13.384539604187012, EPOCH: 27\n",
      "Train Accuracy: 7.735025405883789, EPOCH: 28\n",
      "Validation Accuracy: 38.30421829223633, EPOCH: 28\n",
      "Train Accuracy: 8.939154624938965, EPOCH: 29\n",
      "Validation Accuracy: nan, EPOCH: 29\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float16').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-bfa5974dfc91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mlosses_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-bfa5974dfc91>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Accuracy: {val_loss.item()}, EPOCH: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \"\"\"\n\u001b[0;32m--> 423\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     )\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float16')."
     ]
    }
   ],
   "source": [
    "# Добавил scaler и mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5, weight_decay=5e-4)\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "device = \"cuda:2\"\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for data in loader:  # Iterate in batches over the training dataset.\n",
    "\n",
    "            out = model(data.to(device))  # Perform a single forward pass.\n",
    "            loss = criterion(out.view(-1, 1), data.y.view(-1, 1))  # Compute the loss.\n",
    "            scaler.scale(loss).backward()  # Derive gradients.\n",
    "            # loss.backward()\n",
    "            scaler.step(optimizer)  # Update parameters based on gradients.\n",
    "            # optimizer.step()\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "            true_labels.extend(data.y.detach().cpu().numpy())\n",
    "            pred_labels.extend(out.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Train Accuracy: {loss.item()}, EPOCH: {epoch}\")\n",
    "\n",
    "    return loss.item(), mean_squared_error(true_labels, pred_labels)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "                out = model(data.to(device))\n",
    "                val_loss = criterion(out.view(-1, 1), data.y.view(-1, 1))\n",
    "\n",
    "                true_labels.extend(data.y.detach().cpu().numpy())\n",
    "                pred_labels.extend(out.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Validation Accuracy: {val_loss.item()}, EPOCH: {epoch}\")\n",
    "    return val_loss.item(), mean_squared_error(true_labels, pred_labels)\n",
    "\n",
    "\n",
    "losses_d = {\"train\": [], \"val\": [], \"train_rmse\": [], \"val_rmse\": []}\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss, train_rmse = train(train_loader)\n",
    "    val_loss, test_rmse = test(test_loader)\n",
    "\n",
    "    losses_d[\"train\"].append(train_loss)\n",
    "    losses_d[\"val\"].append(val_loss)\n",
    "    losses_d[\"train_rmse\"].append(train_rmse)\n",
    "    losses_d[\"val_rmse\"].append(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "196ac9c1-16d9-440d-96c3-bbe0bb061ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train', 2.50496244430542),\n",
       " ('val', 1.0628594160079956),\n",
       " ('train_rmse', 7.292406),\n",
       " ('val_rmse', 8.242118)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, min(losses_d[i])) for i in losses_d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ed6c2-c25b-427d-8ab9-06db9f50b009",
   "metadata": {},
   "source": [
    "Хуже бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc4d41cc-1439-4fc4-8004-8b9b73acb581",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.004145525395870209\n",
      "Validation loss: 6.749276161193848\n",
      "Train loss: 0.6910750269889832\n",
      "Validation loss: 7.386547088623047\n",
      "Train loss: 55.16569519042969\n",
      "Validation loss: 0.013981571421027184\n",
      "Train loss: 0.00685677956789732\n",
      "Validation loss: 10.361148834228516\n",
      "Train loss: 0.43512243032455444\n",
      "Validation loss: 0.10570701956748962\n",
      "Train loss: 30.593734741210938\n",
      "Validation loss: 33.584102630615234\n",
      "Train loss: 14.447463989257812\n",
      "Validation loss: 18.585309982299805\n",
      "Train loss: 16.565887451171875\n",
      "Validation loss: 0.8509278297424316\n",
      "Train loss: 67.62338256835938\n",
      "Validation loss: 59.572933197021484\n",
      "Train loss: 0.24486319720745087\n",
      "Validation loss: 101.80974578857422\n",
      "Train loss: 0.22299863398075104\n",
      "Validation loss: 4.253596782684326\n",
      "Train loss: 2.8511979579925537\n",
      "Validation loss: 111.56334686279297\n",
      "Train loss: 53.951438903808594\n",
      "Validation loss: 41.51873779296875\n",
      "Train loss: 0.15356935560703278\n",
      "Validation loss: 1.7616194486618042\n",
      "Train loss: 0.9798112511634827\n",
      "Validation loss: 0.019700046628713608\n",
      "Train loss: 47.00020980834961\n",
      "Validation loss: 61.89385223388672\n",
      "Train loss: 55.842140197753906\n",
      "Validation loss: 0.018579348921775818\n",
      "Train loss: 6.200942039489746\n",
      "Validation loss: 0.0018108810763806105\n",
      "Train loss: 70.71611785888672\n",
      "Validation loss: 2.354140520095825\n",
      "Train loss: 0.008170297369360924\n",
      "Validation loss: 123.17269134521484\n",
      "Train loss: 58.82463455200195\n",
      "Validation loss: 46.1682014465332\n",
      "Train loss: 0.0028715734370052814\n",
      "Validation loss: 102.71800231933594\n",
      "Train loss: 55.5181884765625\n",
      "Validation loss: 5.835721969604492\n",
      "Train loss: 45.50309753417969\n",
      "Validation loss: 2.150798797607422\n",
      "Train loss: 0.24392329156398773\n",
      "Validation loss: 1.0234367847442627\n",
      "Train loss: 83.38127136230469\n",
      "Validation loss: 0.8509278297424316\n",
      "Train loss: 18.091894149780273\n",
      "Validation loss: 117.96250915527344\n",
      "Train loss: 0.7138460278511047\n",
      "Validation loss: 1.493438720703125\n",
      "Train loss: 1.7913542985916138\n",
      "Validation loss: 0.03812284767627716\n",
      "Train loss: 87.01396179199219\n",
      "Validation loss: 0.6829155087471008\n",
      "Train loss: 36.224430084228516\n",
      "Validation loss: 6.0966477394104\n",
      "Train loss: 0.005526611115783453\n",
      "Validation loss: 11.654379844665527\n",
      "Train loss: 0.7131118178367615\n",
      "Validation loss: 59.21230697631836\n",
      "Train loss: 33.8568115234375\n",
      "Validation loss: 0.6322318315505981\n",
      "Train loss: 0.003460898296907544\n",
      "Validation loss: 7.164790153503418\n",
      "Train loss: 44.00849533081055\n",
      "Validation loss: 0.870108962059021\n",
      "Train loss: 40.890708923339844\n",
      "Validation loss: 7.150795936584473\n",
      "Train loss: 44.69637680053711\n",
      "Validation loss: 0.01117996871471405\n",
      "Train loss: 16.325302124023438\n",
      "Validation loss: 0.002932497765868902\n",
      "Train loss: 156.89553833007812\n",
      "Validation loss: 74.46389770507812\n",
      "Train loss: 58.358741760253906\n",
      "Validation loss: 36.013031005859375\n",
      "Train loss: 21.215539932250977\n",
      "Validation loss: 11.530945777893066\n",
      "Train loss: 4.184685707092285\n",
      "Validation loss: 0.04553013667464256\n",
      "Train loss: 49.90085983276367\n",
      "Validation loss: 0.0037781731225550175\n",
      "Train loss: 0.002861679531633854\n",
      "Validation loss: 105.1837158203125\n",
      "Train loss: 1.9587132930755615\n",
      "Validation loss: 39.08868408203125\n",
      "Train loss: 6.986009120941162\n",
      "Validation loss: 7.339682579040527\n",
      "Train loss: 21.973007202148438\n",
      "Validation loss: 0.006314963102340698\n",
      "Train loss: 22.8918399810791\n",
      "Validation loss: 85.16726684570312\n",
      "Train loss: 119.78369140625\n",
      "Validation loss: 140.37127685546875\n",
      "Train loss: 120.97017669677734\n",
      "Validation loss: 2.0062010288238525\n",
      "Train loss: 12.297028541564941\n",
      "Validation loss: 58.84797668457031\n",
      "Train loss: 46.66548156738281\n",
      "Validation loss: 0.9091496467590332\n",
      "Train loss: 33.83515167236328\n",
      "Validation loss: 0.14403674006462097\n",
      "Train loss: 0.5629130005836487\n",
      "Validation loss: 54.55690002441406\n",
      "Train loss: 0.3061773180961609\n",
      "Validation loss: 21.603107452392578\n",
      "Train loss: 0.5558615922927856\n",
      "Validation loss: 0.43234360218048096\n",
      "Train loss: 0.003500866936519742\n",
      "Validation loss: 0.05129373446106911\n",
      "Train loss: 162.3223114013672\n",
      "Validation loss: 0.08329705148935318\n",
      "Train loss: 0.5082798600196838\n",
      "Validation loss: 41.64664077758789\n",
      "Train loss: 3.8275187015533447\n",
      "Validation loss: 1.7598493099212646\n",
      "Train loss: 0.018312737345695496\n",
      "Validation loss: 0.49469274282455444\n",
      "Train loss: 38.026763916015625\n",
      "Validation loss: 33.79829025268555\n",
      "Train loss: 83.71065521240234\n",
      "Validation loss: 24.876108169555664\n",
      "Train loss: 0.021769171580672264\n",
      "Validation loss: 40.88368606567383\n",
      "Train loss: 0.0609901025891304\n",
      "Validation loss: 0.0038984743878245354\n",
      "Train loss: 88.94308471679688\n",
      "Validation loss: 82.68794250488281\n",
      "Train loss: 58.24704360961914\n",
      "Validation loss: 12.26370620727539\n",
      "Train loss: 0.027341315522789955\n",
      "Validation loss: 0.003865652484819293\n",
      "Train loss: 79.07682800292969\n",
      "Validation loss: 0.07471597194671631\n",
      "Train loss: 1.9428622722625732\n",
      "Validation loss: 125.6321029663086\n",
      "Train loss: 5.012332439422607\n",
      "Validation loss: 82.64476776123047\n",
      "Train loss: 8.796782493591309\n",
      "Validation loss: 15.54498291015625\n",
      "Train loss: 45.322994232177734\n",
      "Validation loss: 0.8805243372917175\n",
      "Train loss: 0.006622932851314545\n",
      "Validation loss: 8.850234985351562\n",
      "Train loss: 8.803050994873047\n",
      "Validation loss: 1.964779257774353\n",
      "Train loss: 0.0584065206348896\n",
      "Validation loss: 76.21664428710938\n",
      "Train loss: 22.810087203979492\n",
      "Validation loss: 1.8894822597503662\n",
      "Train loss: 0.006032929290086031\n",
      "Validation loss: 39.52166748046875\n",
      "Train loss: 43.56133270263672\n",
      "Validation loss: 123.19514465332031\n",
      "Train loss: 2.9116902351379395\n",
      "Validation loss: 7.68757963180542\n",
      "Train loss: 18.041292190551758\n",
      "Validation loss: 52.60102844238281\n",
      "Train loss: 1.673033595085144\n",
      "Validation loss: 0.004121006932109594\n",
      "Train loss: 89.94427490234375\n",
      "Validation loss: 0.3734314739704132\n",
      "Train loss: 0.0029711085371673107\n",
      "Validation loss: 0.5630311965942383\n",
      "Train loss: 15.400994300842285\n",
      "Validation loss: 48.574012756347656\n",
      "Train loss: 0.0017893078038468957\n",
      "Validation loss: 0.05071811005473137\n",
      "Train loss: 58.45667266845703\n",
      "Validation loss: 15.54498291015625\n",
      "Train loss: 3.3618273735046387\n",
      "Validation loss: 0.021138302981853485\n",
      "Train loss: 0.052590999752283096\n",
      "Validation loss: 6.787697792053223\n",
      "Train loss: 13.702265739440918\n",
      "Validation loss: 58.69987106323242\n",
      "Train loss: 2.8247623443603516\n",
      "Validation loss: 125.63412475585938\n",
      "Train loss: 0.0029264253098517656\n",
      "Validation loss: 123.55812072753906\n",
      "Train loss: 0.042359668761491776\n",
      "Validation loss: 1.0051255226135254\n",
      "Train loss: 0.1765226572751999\n",
      "Validation loss: 9.85495662689209\n",
      "Train loss: 20.960187911987305\n",
      "Validation loss: 0.2786596715450287\n",
      "Train loss: 9.495362281799316\n",
      "Validation loss: 0.6331654191017151\n",
      "Train loss: 0.9847579002380371\n",
      "Validation loss: 62.79029846191406\n",
      "Train loss: 43.866477966308594\n",
      "Validation loss: 0.0022100755013525486\n",
      "Train loss: 10.610404968261719\n",
      "Validation loss: 3.6293044090270996\n"
     ]
    }
   ],
   "source": [
    "# Возможно, scaler и mixed precision всё ломают...\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5, weight_decay=5e-4)\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "device = \"cuda:2\"\n",
    "model = MyDeeperGCN(\n",
    "    train_dataset.num_node_features,\n",
    "    train_dataset.num_edge_features,\n",
    "    node_hidden_channels=64,\n",
    "    edge_hidden_channels=64,\n",
    "    num_layers=3,\n",
    "    num_classes=1,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(out.view(-1, 1), data.y.view(-1, 1))  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "    print(f\"Train loss: {loss.item()}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        true = []\n",
    "        preds = []\n",
    "        for data in test_loader:  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            out = model(data)  # Perform a single forward pass.\n",
    "            val_loss = criterion(\n",
    "                out.view(-1, 1), data.y.view(-1, 1)\n",
    "            )  # Compute the loss.\n",
    "            true.extend(data.y.detach().cpu().numpy())\n",
    "            preds.extend(out.detach().cpu().numpy())\n",
    "        print(f\"Validation loss: {val_loss.item()}\")\n",
    "\n",
    "    return mean_squared_error(true, preds)\n",
    "\n",
    "\n",
    "rmse_history = []\n",
    "for epoch in range(100):\n",
    "    rmse_val = train()\n",
    "    rmse_history.append(rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b680804b-46a2-4ca2-9abb-f555ff1e5be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, 20.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmse_history)\n",
    "plt.title(\"RMSE history for heavy graph model\")\n",
    "plt.ylim([3, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc488084-f65c-45bb-8b28-1054ecba2a7a",
   "metadata": {},
   "source": [
    "Нет, без scaler и mixed_precision всё еще хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846625c0-c4e9-4293-a2b9-cdf3fcc200df",
   "metadata": {},
   "source": [
    "# Simple non-graph model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81ad79b2-e52c-4d6c-b93a-3a42ec2f12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph_data = self.graphs[idx]\n",
    "\n",
    "        graph_data.y_exp = torch.exp(deepcopy(graph_data.y))\n",
    "\n",
    "        graph_data.y_int = torch.round(deepcopy(graph_data.y_exp)).float()\n",
    "\n",
    "        return F.pad(graph_data.x, (0, 0, 538 - graph_data.x.shape[0], 0)), graph_data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "68221d05-a01b-4d81-a7f9-581aaf20d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphDataset(X_train)\n",
    "test_dataset = GraphDataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc762186-4c23-48f5-93e9-a34f72aa08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "30edfcd4-5c5a-4f20-afac-2de7e8a09f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 538, 27])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b7d5f442-82e7-4134-9b9d-788eb4e08d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (node1): Linear(in_features=27, out_features=30, bias=True)\n",
      "  (node2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (node3): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (lin1): Linear(in_features=538, out_features=250, bias=True)\n",
      "  (lin2): Linear(in_features=250, out_features=125, bias=True)\n",
      "  (lin3): Linear(in_features=125, out_features=50, bias=True)\n",
      "  (lin4): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n",
      "174277\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.node1 = Linear(27, 30)\n",
    "        self.node2 = Linear(30, 30)\n",
    "        self.node3 = Linear(30, 1)\n",
    "\n",
    "        self.lin1 = Linear(538, 250)\n",
    "        self.lin2 = Linear(250, 125)\n",
    "        self.lin3 = Linear(125, 50)\n",
    "        self.lin4 = Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Obtain node embeddings\n",
    "\n",
    "        x = self.node1(x)\n",
    "        x = x.relu()\n",
    "        x = self.node2(x)\n",
    "        x = x.relu()\n",
    "        x = self.node3(x)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        emb = self.lin1(x)\n",
    "        emb = emb.relu()\n",
    "        emb = self.lin2(emb)\n",
    "        emb = emb.relu()\n",
    "        emb = self.lin3(emb)\n",
    "        emb = emb.relu()\n",
    "        emb = self.lin4(emb)\n",
    "\n",
    "        return emb\n",
    "\n",
    "\n",
    "model = SimpleNet()\n",
    "print(model)\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a0ba8435-798b-4d8b-8008-1a75d9dcb134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0018012098735198379\n",
      "Validation loss: 9.810657501220703\n",
      "Train loss: 0.0006994596333242953\n",
      "Validation loss: 3.1569535732269287\n",
      "Train loss: 0.036039017140865326\n",
      "Validation loss: 7.76141357421875\n",
      "Train loss: 0.008190817199647427\n",
      "Validation loss: 0.9339948296546936\n",
      "Train loss: 0.01852126233279705\n",
      "Validation loss: 7.070501804351807\n",
      "Train loss: 0.024220522493124008\n",
      "Validation loss: 72.6246109008789\n",
      "Train loss: 0.00018819286196958274\n",
      "Validation loss: 0.031264081597328186\n",
      "Train loss: 0.6099826693534851\n",
      "Validation loss: 0.3196589946746826\n",
      "Train loss: 0.01178784854710102\n",
      "Validation loss: 0.16399696469306946\n",
      "Train loss: 0.13650275766849518\n",
      "Validation loss: 0.20345750451087952\n",
      "Train loss: 0.1401083767414093\n",
      "Validation loss: 20.592247009277344\n",
      "Train loss: 0.0249974112957716\n",
      "Validation loss: 0.8318202495574951\n",
      "Train loss: 0.012425193563103676\n",
      "Validation loss: 0.24594053626060486\n",
      "Train loss: 0.10870187729597092\n",
      "Validation loss: 2.367341995239258\n",
      "Train loss: 0.001739142811857164\n",
      "Validation loss: 16.182579040527344\n",
      "Train loss: 0.008433999493718147\n",
      "Validation loss: 0.4459584951400757\n",
      "Train loss: 0.8773322105407715\n",
      "Validation loss: 0.03098721243441105\n",
      "Train loss: 0.010936789214611053\n",
      "Validation loss: 2.9354164600372314\n",
      "Train loss: 0.017671668902039528\n",
      "Validation loss: 69.69168090820312\n",
      "Train loss: 0.002335868775844574\n",
      "Validation loss: 0.36761102080345154\n",
      "Train loss: 0.1562439650297165\n",
      "Validation loss: 3.019146680831909\n",
      "Train loss: 0.0065406132489442825\n",
      "Validation loss: 11.917194366455078\n",
      "Train loss: 0.012319463305175304\n",
      "Validation loss: 0.18534928560256958\n",
      "Train loss: 0.003278937889263034\n",
      "Validation loss: 0.6546462774276733\n",
      "Train loss: 0.0037869801744818687\n",
      "Validation loss: 0.0148507971316576\n",
      "Train loss: 0.23729290068149567\n",
      "Validation loss: 20.330720901489258\n",
      "Train loss: 0.049518801271915436\n",
      "Validation loss: 4.096787452697754\n",
      "Train loss: 0.005420647095888853\n",
      "Validation loss: 7.903639316558838\n",
      "Train loss: 0.025250814855098724\n",
      "Validation loss: 3.6847517490386963\n",
      "Train loss: 0.012746697291731834\n",
      "Validation loss: 1.6155763864517212\n",
      "Train loss: 0.038401417434215546\n",
      "Validation loss: 11.136764526367188\n",
      "Train loss: 0.33833131194114685\n",
      "Validation loss: 58.34799575805664\n",
      "Train loss: 0.09674283117055893\n",
      "Validation loss: 7.6656174659729\n",
      "Train loss: 0.04644006863236427\n",
      "Validation loss: 7.254859447479248\n",
      "Train loss: 0.03704153001308441\n",
      "Validation loss: 2.177886486053467\n",
      "Train loss: 0.004482465796172619\n",
      "Validation loss: 6.964737892150879\n",
      "Train loss: 0.002294919453561306\n",
      "Validation loss: 0.1108822375535965\n",
      "Train loss: 0.0006644458044320345\n",
      "Validation loss: 70.62164306640625\n",
      "Train loss: 0.014553690329194069\n",
      "Validation loss: 0.38202324509620667\n",
      "Train loss: 0.0011044880375266075\n",
      "Validation loss: 69.86209106445312\n",
      "Train loss: 0.02294539101421833\n",
      "Validation loss: 4.92626428604126\n",
      "Train loss: 0.01183445192873478\n",
      "Validation loss: 0.6456347703933716\n",
      "Train loss: 0.00046338955871760845\n",
      "Validation loss: 0.0349288284778595\n",
      "Train loss: 0.06008341908454895\n",
      "Validation loss: 0.10712424665689468\n",
      "Train loss: 0.03559776395559311\n",
      "Validation loss: 3.3055360317230225\n",
      "Train loss: 0.0008911279146559536\n",
      "Validation loss: 0.6002157926559448\n",
      "Train loss: 0.27040958404541016\n",
      "Validation loss: 1.0497064590454102\n",
      "Train loss: 0.00548435328528285\n",
      "Validation loss: 5.664312362670898\n",
      "Train loss: 0.018281709402799606\n",
      "Validation loss: 4.547050476074219\n",
      "Train loss: 0.00018807582091540098\n",
      "Validation loss: 3.089927911758423\n",
      "Train loss: 0.0019893269054591656\n",
      "Validation loss: 0.2909839153289795\n",
      "Train loss: 0.006163698621094227\n",
      "Validation loss: 0.7907745838165283\n",
      "Train loss: 0.021784603595733643\n",
      "Validation loss: 0.5754227638244629\n",
      "Train loss: 0.0014227547217160463\n",
      "Validation loss: 3.5122110843658447\n",
      "Train loss: 0.009546623565256596\n",
      "Validation loss: 0.8201549053192139\n",
      "Train loss: 0.0030273899901658297\n",
      "Validation loss: 1.048458456993103\n",
      "Train loss: 0.029698537662625313\n",
      "Validation loss: 5.804842948913574\n",
      "Train loss: 0.005189224611967802\n",
      "Validation loss: 0.10096398741006851\n",
      "Train loss: 0.0074780662544071674\n",
      "Validation loss: 0.24222703278064728\n",
      "Train loss: 0.5531231760978699\n",
      "Validation loss: 9.46988582611084\n",
      "Train loss: 0.03572198748588562\n",
      "Validation loss: 0.10196833312511444\n",
      "Train loss: 0.0007288926281034946\n",
      "Validation loss: 34.383182525634766\n",
      "Train loss: 0.0031142160296440125\n",
      "Validation loss: 4.013664245605469\n",
      "Train loss: 0.0012576926965266466\n",
      "Validation loss: 4.58852481842041\n",
      "Train loss: 0.0031398634891957045\n",
      "Validation loss: 11.027594566345215\n",
      "Train loss: 0.1251104325056076\n",
      "Validation loss: 0.2091398537158966\n",
      "Train loss: 0.010055014863610268\n",
      "Validation loss: 27.830745697021484\n",
      "Train loss: 0.028290409594774246\n",
      "Validation loss: 0.00993295293301344\n",
      "Train loss: 0.20287683606147766\n",
      "Validation loss: 0.020633570849895477\n",
      "Train loss: 6.148396641947329e-05\n",
      "Validation loss: 18.786653518676758\n",
      "Train loss: 0.049231626093387604\n",
      "Validation loss: 27.925148010253906\n",
      "Train loss: 0.23713168501853943\n",
      "Validation loss: 52.38156509399414\n",
      "Train loss: 0.0010848235106095672\n",
      "Validation loss: 1.2500226497650146\n",
      "Train loss: 0.03795815259218216\n",
      "Validation loss: 7.651742935180664\n",
      "Train loss: 0.025069890543818474\n",
      "Validation loss: 1.9984893798828125\n",
      "Train loss: 0.001143584493547678\n",
      "Validation loss: 2.2374114990234375\n",
      "Train loss: 0.0011345152743160725\n",
      "Validation loss: 22.314006805419922\n",
      "Train loss: 0.018009591847658157\n",
      "Validation loss: 0.02634209208190441\n",
      "Train loss: 0.0002039530227193609\n",
      "Validation loss: 0.7466001510620117\n",
      "Train loss: 0.011907301843166351\n",
      "Validation loss: 0.00014847438433207572\n",
      "Train loss: 0.0039960178546607494\n",
      "Validation loss: 4.229861259460449\n",
      "Train loss: 0.0025436573196202517\n",
      "Validation loss: 0.9446417093276978\n",
      "Train loss: 0.00033100583823397756\n",
      "Validation loss: 3.2062747478485107\n",
      "Train loss: 0.050831399857997894\n",
      "Validation loss: 5.236867904663086\n",
      "Train loss: 0.0003197368641849607\n",
      "Validation loss: 5.36415958404541\n",
      "Train loss: 0.007480249740183353\n",
      "Validation loss: 3.2175097465515137\n",
      "Train loss: 0.05594799295067787\n",
      "Validation loss: 1.070814609527588\n",
      "Train loss: 0.018446341156959534\n",
      "Validation loss: 3.465428113937378\n",
      "Train loss: 0.0006126331863924861\n",
      "Validation loss: 8.26522159576416\n",
      "Train loss: 0.0015239025233313441\n",
      "Validation loss: 12.260272979736328\n",
      "Train loss: 0.001940209767781198\n",
      "Validation loss: 8.22289752960205\n",
      "Train loss: 0.001744340406730771\n",
      "Validation loss: 1.4186735153198242\n",
      "Train loss: 0.001096592633984983\n",
      "Validation loss: 22.441669464111328\n",
      "Train loss: 0.004957115743309259\n",
      "Validation loss: 1.987733244895935\n",
      "Train loss: 0.03923611715435982\n",
      "Validation loss: 5.60020637512207\n",
      "Train loss: 0.009063417091965675\n",
      "Validation loss: 3.5166308879852295\n",
      "Train loss: 0.048067186027765274\n",
      "Validation loss: 16.106294631958008\n",
      "Train loss: 0.10345607250928879\n",
      "Validation loss: 0.5258544087409973\n",
      "Train loss: 5.0561382522573695e-05\n",
      "Validation loss: 0.3792620897293091\n",
      "Train loss: 0.001949281431734562\n",
      "Validation loss: 0.5871536731719971\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "device = \"cuda:2\"\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data, y in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        y = y.to(device)\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(out.view(-1, 1), y.view(-1, 1))  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "    print(f\"Train loss: {loss.item()}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        true = []\n",
    "        preds = []\n",
    "        for data, y in test_loader:  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(data)  # Perform a single forward pass.\n",
    "            val_loss = criterion(out.view(-1, 1), y.view(-1, 1))  # Compute the loss.\n",
    "            true.extend(y.detach().cpu().numpy())\n",
    "            preds.extend(out.detach().cpu().numpy())\n",
    "        print(f\"Validation loss: {val_loss.item()}\")\n",
    "\n",
    "    return mean_squared_error(true, preds)\n",
    "\n",
    "\n",
    "rmse_history = []\n",
    "for epoch in range(100):\n",
    "    rmse_val = train()\n",
    "    rmse_history.append(rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "738d8cc7-e8f2-4fe9-ac55-006b173a1f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, 20.0)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmse_history)\n",
    "plt.title(\"RMSE history for simple non-graph model\")\n",
    "plt.ylim([3, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e64f3727-5416-477d-9ba3-264e36b4d917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.578388"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(rmse_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2546ca8-5d26-4063-a71a-f3c1108c62f1",
   "metadata": {},
   "source": [
    "Очень медленная и плохая сходимость на +- уровень бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae900b1-7611-4874-b900-a08d5568b079",
   "metadata": {},
   "source": [
    "# GRU - вариант очень большой сети, учитывающей edge_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec73780-1d63-4bfe-8839-69dc48979ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import GRU, Linear, ReLU, Sequential\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "\n",
    "device = \"cuda:2\"\n",
    "\n",
    "\n",
    "class MPNNet(torch.nn.Module):\n",
    "    def __init__(self, node_feats, channels, out_feats, loops=1, edge_feats=1):\n",
    "        super(MPNNet, self).__init__()\n",
    "        self.lin0 = torch.nn.Linear(node_feats, channels)\n",
    "        self.loops = loops\n",
    "        nn = Sequential(\n",
    "            Linear(edge_feats, channels), ReLU(), Linear(channels, channels * channels)\n",
    "        )\n",
    "        self.conv = NNConv(channels, channels, nn, aggr=\"mean\")\n",
    "        self.gru = GRU(channels, channels)\n",
    "        self.set2set = Set2Set(channels, 1)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(channels * 2, channels)\n",
    "        self.lin2 = torch.nn.Linear(channels, out_feats)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.lin0(data.x.float()))\n",
    "        h = out.unsqueeze(0)\n",
    "\n",
    "        for i in range(self.loops):\n",
    "            m = F.relu(\n",
    "                self.conv(out.float(), data.edge_index.long(), data.edge_attr.float())\n",
    "            )\n",
    "            out, h = self.gru(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "\n",
    "        out = self.set2set(out, data.batch)\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f591f8f2-c964-4f2b-82ea-8581b26f31bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2463873\n"
     ]
    }
   ],
   "source": [
    "node_feats = train_dataset.num_node_features\n",
    "out_feats = 1\n",
    "edge_feats = train_dataset.num_edge_features\n",
    "\n",
    "\n",
    "# model = GCNNet(node_feats,256,out_feats,edge_feats=edge_feats).double().to(device)\n",
    "model = MPNNet(node_feats, 128, out_feats, loops=10, edge_feats=edge_feats).float()\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ea55313-6218-48a8-9792-a4745c8f270e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNNet(\n",
       "  (lin0): Linear(in_features=27, out_features=128, bias=True)\n",
       "  (conv): NNConv(128, 128, aggr=\"mean\", nn=Sequential(\n",
       "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=16384, bias=True)\n",
       "  ))\n",
       "  (gru): GRU(128, 128)\n",
       "  (set2set): Set2Set(128, 256)\n",
       "  (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb5a9b94-6bef-4ca4-82de-d1e5c4742123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f78583c5-700c-409b-9bac-dccd633d1a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 96.58198547363281, EPOCH: 0, rmse 10.253569602966309\n",
      "Validation Accuracy: 0.864886462688446, EPOCH: 0, rmse 9.822648048400879\n",
      "Train Accuracy: 1.5249669551849365, EPOCH: 1, rmse 8.165838241577148\n",
      "Validation Accuracy: 2.3352818489074707, EPOCH: 1, rmse 8.906861305236816\n",
      "Train Accuracy: 5.291328430175781, EPOCH: 2, rmse 7.641041278839111\n",
      "Validation Accuracy: 3.614690065383911, EPOCH: 2, rmse 8.542835235595703\n",
      "Train Accuracy: 4.628066539764404, EPOCH: 3, rmse 7.5419416427612305\n",
      "Validation Accuracy: 0.576270341873169, EPOCH: 3, rmse 8.520788192749023\n",
      "Train Accuracy: 7.228550434112549, EPOCH: 4, rmse 7.524672031402588\n",
      "Validation Accuracy: 75.2681655883789, EPOCH: 4, rmse 8.497868537902832\n",
      "Train Accuracy: 24.049753189086914, EPOCH: 5, rmse 7.482661724090576\n",
      "Validation Accuracy: 42.1541748046875, EPOCH: 5, rmse 9.975358009338379\n",
      "Train Accuracy: 5.114821434020996, EPOCH: 6, rmse 7.428972244262695\n",
      "Validation Accuracy: 43.04279327392578, EPOCH: 6, rmse 8.4843168258667\n",
      "Train Accuracy: 4.4300360679626465, EPOCH: 7, rmse 7.545198917388916\n",
      "Validation Accuracy: 4.762639999389648, EPOCH: 7, rmse 8.792746543884277\n",
      "Train Accuracy: 22.393882751464844, EPOCH: 8, rmse 7.535412788391113\n",
      "Validation Accuracy: 4.102154731750488, EPOCH: 8, rmse 8.467951774597168\n",
      "Train Accuracy: 5.714465141296387, EPOCH: 9, rmse 7.533057689666748\n",
      "Validation Accuracy: 3.8534622192382812, EPOCH: 9, rmse 8.453272819519043\n",
      "Train Accuracy: 7.315574645996094, EPOCH: 10, rmse 7.379501819610596\n",
      "Validation Accuracy: 33.227882385253906, EPOCH: 10, rmse 8.46037769317627\n",
      "Train Accuracy: 0.10125526040792465, EPOCH: 11, rmse 7.248349666595459\n",
      "Validation Accuracy: 8.8388671875, EPOCH: 11, rmse 8.440166473388672\n",
      "Train Accuracy: 8.116168022155762, EPOCH: 12, rmse 7.5225911140441895\n",
      "Validation Accuracy: 5.115835666656494, EPOCH: 12, rmse 8.281932830810547\n",
      "Train Accuracy: 5.081150054931641, EPOCH: 13, rmse 7.295955657958984\n",
      "Validation Accuracy: 3.353348970413208, EPOCH: 13, rmse 8.497766494750977\n",
      "Train Accuracy: 9.434663772583008, EPOCH: 14, rmse 7.230119705200195\n",
      "Validation Accuracy: 25.88670539855957, EPOCH: 14, rmse 8.347466468811035\n",
      "Train Accuracy: 15.536176681518555, EPOCH: 15, rmse 7.415096282958984\n",
      "Validation Accuracy: 7.73876428604126, EPOCH: 15, rmse 8.32239055633545\n",
      "Train Accuracy: 16.408260345458984, EPOCH: 16, rmse 7.2573137283325195\n",
      "Validation Accuracy: 7.112748146057129, EPOCH: 16, rmse 8.046552658081055\n",
      "Train Accuracy: 2.053645610809326, EPOCH: 17, rmse 7.222749710083008\n",
      "Validation Accuracy: 41.30801773071289, EPOCH: 17, rmse 10.257013320922852\n",
      "Train Accuracy: 7.861680030822754, EPOCH: 18, rmse 7.221111297607422\n",
      "Validation Accuracy: 1.9137778282165527, EPOCH: 18, rmse 8.394935607910156\n",
      "Train Accuracy: 8.00278091430664, EPOCH: 19, rmse 7.468297004699707\n",
      "Validation Accuracy: 68.22471618652344, EPOCH: 19, rmse 8.185212135314941\n",
      "Train Accuracy: 15.932282447814941, EPOCH: 20, rmse 7.269417762756348\n",
      "Validation Accuracy: 8.575006484985352, EPOCH: 20, rmse 8.006664276123047\n",
      "Train Accuracy: 5.224826335906982, EPOCH: 21, rmse 7.203155994415283\n",
      "Validation Accuracy: 29.58382797241211, EPOCH: 21, rmse 7.973043441772461\n",
      "Train Accuracy: 30.899658203125, EPOCH: 22, rmse 7.159491062164307\n",
      "Validation Accuracy: 1.834694743156433, EPOCH: 22, rmse 8.170475006103516\n",
      "Train Accuracy: 0.002772081410512328, EPOCH: 23, rmse 7.16246223449707\n",
      "Validation Accuracy: 15.20571231842041, EPOCH: 23, rmse 7.991468906402588\n",
      "Train Accuracy: 41.37215805053711, EPOCH: 24, rmse 7.214895248413086\n",
      "Validation Accuracy: 4.654028415679932, EPOCH: 24, rmse 8.104111671447754\n",
      "Train Accuracy: 6.433789253234863, EPOCH: 25, rmse 7.150816440582275\n",
      "Validation Accuracy: 10.84136962890625, EPOCH: 25, rmse 7.914213180541992\n",
      "Train Accuracy: 6.061633586883545, EPOCH: 26, rmse 7.135519981384277\n",
      "Validation Accuracy: 0.5697722434997559, EPOCH: 26, rmse 11.105116844177246\n",
      "Train Accuracy: 5.593196392059326, EPOCH: 27, rmse 7.308290004730225\n",
      "Validation Accuracy: 13.379575729370117, EPOCH: 27, rmse 8.358216285705566\n",
      "Train Accuracy: 7.703954219818115, EPOCH: 28, rmse 7.475020885467529\n",
      "Validation Accuracy: 4.281898021697998, EPOCH: 28, rmse 8.236847877502441\n",
      "Train Accuracy: 2.0832715034484863, EPOCH: 29, rmse 7.295649528503418\n",
      "Validation Accuracy: 2.1650402545928955, EPOCH: 29, rmse 8.043639183044434\n",
      "Train Accuracy: 29.86408042907715, EPOCH: 30, rmse 7.222597599029541\n",
      "Validation Accuracy: 7.058403968811035, EPOCH: 30, rmse 7.984957695007324\n",
      "Train Accuracy: 28.583967208862305, EPOCH: 31, rmse 7.197993278503418\n",
      "Validation Accuracy: 33.82952117919922, EPOCH: 31, rmse 7.95899772644043\n",
      "Train Accuracy: 27.319276809692383, EPOCH: 32, rmse 7.166889190673828\n",
      "Validation Accuracy: 3.7370338439941406, EPOCH: 32, rmse 8.027976036071777\n",
      "Train Accuracy: 33.183006286621094, EPOCH: 33, rmse 7.133100509643555\n",
      "Validation Accuracy: 66.18843078613281, EPOCH: 33, rmse 7.903921127319336\n",
      "Train Accuracy: 4.508174419403076, EPOCH: 34, rmse 7.082700252532959\n",
      "Validation Accuracy: 2.6233582496643066, EPOCH: 34, rmse 8.41241455078125\n",
      "Train Accuracy: 5.0906500816345215, EPOCH: 35, rmse 7.077075004577637\n",
      "Validation Accuracy: 10.025354385375977, EPOCH: 35, rmse 7.932793140411377\n",
      "Train Accuracy: 8.831880569458008, EPOCH: 36, rmse 7.152849197387695\n",
      "Validation Accuracy: 44.870182037353516, EPOCH: 36, rmse 9.064311981201172\n",
      "Train Accuracy: 3.9789628982543945, EPOCH: 37, rmse 7.207659721374512\n",
      "Validation Accuracy: 13.653247833251953, EPOCH: 37, rmse 8.15979290008545\n",
      "Train Accuracy: 9.479961395263672, EPOCH: 38, rmse 7.313493728637695\n",
      "Validation Accuracy: 7.915593147277832, EPOCH: 38, rmse 8.197309494018555\n",
      "Train Accuracy: 9.503313064575195, EPOCH: 39, rmse 7.116801738739014\n",
      "Validation Accuracy: 1.524405598640442, EPOCH: 39, rmse 7.854869842529297\n",
      "Train Accuracy: 29.513622283935547, EPOCH: 40, rmse 7.027651309967041\n",
      "Validation Accuracy: 3.3161094188690186, EPOCH: 40, rmse 8.356667518615723\n",
      "Train Accuracy: 0.007659143768250942, EPOCH: 41, rmse 7.005862236022949\n",
      "Validation Accuracy: 13.811922073364258, EPOCH: 41, rmse 7.965746879577637\n",
      "Train Accuracy: 17.099109649658203, EPOCH: 42, rmse 7.0998735427856445\n",
      "Validation Accuracy: 0.598738431930542, EPOCH: 42, rmse 9.098541259765625\n",
      "Train Accuracy: 2.7653021812438965, EPOCH: 43, rmse 7.1153435707092285\n",
      "Validation Accuracy: 7.770845890045166, EPOCH: 43, rmse 7.959799766540527\n",
      "Train Accuracy: 15.690552711486816, EPOCH: 44, rmse 7.205268383026123\n",
      "Validation Accuracy: 14.671448707580566, EPOCH: 44, rmse 8.298321723937988\n",
      "Train Accuracy: 2.917664051055908, EPOCH: 45, rmse 7.042011737823486\n",
      "Validation Accuracy: 11.42446517944336, EPOCH: 45, rmse 7.803950786590576\n",
      "Train Accuracy: 23.148324966430664, EPOCH: 46, rmse 6.9620184898376465\n",
      "Validation Accuracy: 0.2854093313217163, EPOCH: 46, rmse 8.47348403930664\n",
      "Train Accuracy: 56.56100845336914, EPOCH: 47, rmse 6.905672550201416\n",
      "Validation Accuracy: 0.7438297867774963, EPOCH: 47, rmse 7.911901473999023\n",
      "Train Accuracy: 11.215937614440918, EPOCH: 48, rmse 7.1368913650512695\n",
      "Validation Accuracy: 2.8215205669403076, EPOCH: 48, rmse 8.471353530883789\n",
      "Train Accuracy: 23.772441864013672, EPOCH: 49, rmse 6.957950592041016\n",
      "Validation Accuracy: 4.123610973358154, EPOCH: 49, rmse 7.8819580078125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5b289c946163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5b289c946163>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Derive gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update parameters based on gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clear gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/user_venv/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=5e-4)\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "device = \"cuda:2\"\n",
    "\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for data in loader:  # Iterate in batches over the training dataset.\n",
    "\n",
    "            out = model(data.to(device))  # Perform a single forward pass.\n",
    "            loss = criterion(out.view(-1, 1), data.y.view(-1, 1))  # Compute the loss.\n",
    "            scaler.scale(loss).backward()  # Derive gradients.\n",
    "            scaler.step(optimizer)  # Update parameters based on gradients.\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "            true_labels.extend(data.y.detach().cpu().numpy())\n",
    "            pred_labels.extend(out.detach().cpu().numpy())\n",
    "\n",
    "    print(\n",
    "        f\"Train Accuracy: {loss.item()}, EPOCH: {epoch}, rmse {mean_squared_error(true_labels, pred_labels)}\"\n",
    "    )\n",
    "\n",
    "    return loss.item(), mean_squared_error(true_labels, pred_labels)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "                out = model(data.to(device))\n",
    "                val_loss = criterion(out.view(-1, 1), data.y.view(-1, 1))\n",
    "\n",
    "                true_labels.extend(data.y.detach().cpu().numpy())\n",
    "                pred_labels.extend(out.detach().cpu().numpy())\n",
    "\n",
    "    print(\n",
    "        f\"Validation Accuracy: {val_loss.item()}, EPOCH: {epoch}, rmse {mean_squared_error(true_labels, pred_labels)}\"\n",
    "    )\n",
    "    return val_loss.item(), mean_squared_error(true_labels, pred_labels)\n",
    "\n",
    "\n",
    "losses_d = {\"train\": [], \"val\": [], \"train_rmse\": [], \"val_rmse\": []}\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss, train_rmse = train(train_loader)\n",
    "    val_loss, test_rmse = test(test_loader)\n",
    "\n",
    "    losses_d[\"train\"].append(train_loss)\n",
    "    losses_d[\"val\"].append(val_loss)\n",
    "    losses_d[\"train_rmse\"].append(train_rmse)\n",
    "    losses_d[\"val_rmse\"].append(test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d694d-b057-4853-9fab-9485eb11c1d3",
   "metadata": {},
   "source": [
    "Производительность не очень хорошая для такой большой модели, слегка лучше бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b73ffa0e-5ba9-4f4f-a915-f6c1ad570199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9fc9e506d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses_d[\"val_rmse\"])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "user_venv",
   "language": "python",
   "name": "user_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
